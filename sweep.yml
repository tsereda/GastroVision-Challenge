program: train.py
method: bayes
metric:
  name: val/balanced_accuracy
  goal: maximize
early_terminate:
  type: hyperband
  min_iter: 15
  eta: 3
  s: 2

parameters:
  model_name:
    value: 'swin_base_patch4_window7_224'
  
  image_size:
    value: 224
  
  # REFINED: Focus on lower LR region (winner was 0.00015)
  learning_rate:
    values: [0.00008, 0.0001, 0.00012, 0.00015]
  
  # REFINED: Stronger bias toward higher weight decay
  weight_decay:
    values: [0.0002, 0.0003, 0.0004]
  
  batch_size:
    value: 32
  
  # INCREASED: More epochs for convergence
  epochs:
    value: 50
  
  # REFINED: Focus on sweet spot
  warmup_epochs:
    values: [10, 12, 14]
  
  scheduler:
    value: 'cosine'
  
  loss_function:
    value: 'focal_weighted'
  
  # CRITICAL: Sweep lower gamma values (negative correlation!)
  # Best run used 1.4, but correlation suggests lower is better
  focal_gamma:
    values: [0.8, 1.0, 1.2, 1.4, 1.6]
  
  # REFINED: Higher values for better smoothing
  label_smoothing:
    values: [0.10, 0.12, 0.15]
  
  # NEW APPROACH: Test both low and high mixup
  mixup_alpha:
    values: [0.05, 0.1, 0.2, 0.3]
  
  # REFINED: Focus on higher cutmix (positive correlation)
  cutmix_alpha:
    values: [0.8, 1.0, 1.2]
  
  mixup_prob:
    values: [0.3, 0.4, 0.5]
  
  # Standard color augmentation
  color_jitter_brightness:
    value: 0.2
  
  color_jitter_contrast:
    value: 0.2
  
  color_jitter_saturation:
    value: 0.2
  
  # REFINED: Higher dropout (positive correlation)
  dropout_rate:
    values: [0.25, 0.3, 0.35]
  
  # REFINED: Focus on higher stochastic depth
  stochastic_depth:
    values: [0.2, 0.25]
  
  # CRITICAL: Aggressive boost for Erythema class
  # Test even higher values to improve worst-class recall
  class_weight_boost:
    values: [2.0, 2.5, 3.0, 3.5, 4.0]